{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation with TF 2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2GAcSkS3mltHrTGTDW+0E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranaya-mathur/Deep-Learning-Projects/blob/master/Translation_with_TF_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9zzVsoJ0XTw",
        "colab_type": "text"
      },
      "source": [
        "[Neural Machine Translation With Attention Mechanism](https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaaN8qAUSaRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b15cf8b3-529d-4766-de5e-2cafb0205c8f"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWdfVDOsS30W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "raw_data = (\n",
        "    ('What a ridiculous concept!', 'Quel concept ridicule !'),\n",
        "    ('Your idea is not entirely crazy.', \"Votre idée n'est pas complètement folle.\"),\n",
        "    (\"A man's worth lies in what he is.\", \"La valeur d'un homme réside dans ce qu'il est.\"),\n",
        "    ('What he did is very wrong.', \"Ce qu'il a fait est très mal.\"),\n",
        "    (\"All three of you need to do that.\", \"Vous avez besoin de faire cela, tous les trois.\"),\n",
        "    (\"Are you giving me another chance?\", \"Me donnez-vous une autre chance ?\"),\n",
        "    (\"Both Tom and Mary work as models.\", \"Tom et Mary travaillent tous les deux comme mannequins.\"),\n",
        "    (\"Can I have a few minutes, please?\", \"Puis-je avoir quelques minutes, je vous prie ?\"),\n",
        "    (\"Could you close the door, please?\", \"Pourriez-vous fermer la porte, s'il vous plaît ?\"),\n",
        "    (\"Did you plant pumpkins this year?\", \"Cette année, avez-vous planté des citrouilles ?\"),\n",
        "    (\"Do you ever study in the library?\", \"Est-ce que vous étudiez à la bibliothèque des fois ?\"),\n",
        "    (\"Don't be deceived by appearances.\", \"Ne vous laissez pas abuser par les apparences.\"),\n",
        "    (\"Excuse me. Can you speak English?\", \"Je vous prie de m'excuser ! Savez-vous parler anglais ?\"),\n",
        "    (\"Few people know the true meaning.\", \"Peu de gens savent ce que cela veut réellement dire.\"),\n",
        "    (\"Germany produced many scientists.\", \"L'Allemagne a produit beaucoup de scientifiques.\"),\n",
        "    (\"Guess whose birthday it is today.\", \"Devine de qui c'est l'anniversaire, aujourd'hui !\"),\n",
        "    (\"He acted like he owned the place.\", \"Il s'est comporté comme s'il possédait l'endroit.\"),\n",
        "    (\"Honesty will pay in the long run.\", \"L'honnêteté paye à la longue.\"),\n",
        "    (\"How do we know this isn't a trap?\", \"Comment savez-vous qu'il ne s'agit pas d'un piège ?\"),\n",
        "    (\"I can't believe you're giving up.\", \"Je n'arrive pas à croire que vous abandonniez.\"),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyFavHj0TSA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-5o1X1zTc7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data_en, raw_data_fr = list(zip(*raw_data))\n",
        "raw_data_en, raw_data_fr = list(raw_data_en), list(raw_data_fr)\n",
        "\n",
        "raw_data_en = [normalize_string(data) for data in raw_data_en]\n",
        "raw_data_fr_in = ['<start> ' + normalize_string(data) for data in raw_data_fr]\n",
        "raw_data_fr_out = [normalize_string(data) + ' <end>' for data in raw_data_fr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO_sjluHUTbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a52f4fca-0554-422b-824e-6d61cf3c7194"
      },
      "source": [
        "raw_data_en[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What a ridiculous concept !',\n",
              " 'Your idea is not entirely crazy .',\n",
              " 'A man s worth lies in what he is .',\n",
              " 'What he did is very wrong .',\n",
              " 'All three of you need to do that .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut8G97xHUVxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "68990065-fb55-4227-ee28-83c677797433"
      },
      "source": [
        "raw_data_fr_in[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> Quel concept ridicule !',\n",
              " '<start> Votre idee n est pas completement folle .',\n",
              " '<start> La valeur d un homme reside dans ce qu il est .',\n",
              " '<start> Ce qu il a fait est tres mal .',\n",
              " '<start> Vous avez besoin de faire cela tous les trois .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiPHhxtSUaze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d9308ef0-7e5a-411b-db7b-525015b068a1"
      },
      "source": [
        "raw_data_fr_out[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Quel concept ridicule ! <end>',\n",
              " 'Votre idee n est pas completement folle . <end>',\n",
              " 'La valeur d un homme reside dans ce qu il est . <end>',\n",
              " 'Ce qu il a fait est tres mal . <end>',\n",
              " 'Vous avez besoin de faire cela tous les trois . <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8835X0ibUyC4",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://machinetalk.org/wp-content/uploads/2019/04/input.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYSmc7Q0UfTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c5be8e64-f3d0-434e-fec8-db0e157cc0ae"
      },
      "source": [
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "en_tokenizer.fit_on_texts(raw_data_en)\n",
        "print(en_tokenizer.word_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'.': 1, 'you': 2, '?': 3, 'the': 4, 'a': 5, 'is': 6, 'he': 7, 'what': 8, 'in': 9, 'do': 10, 'can': 11, 't': 12, 'did': 13, 'giving': 14, 'me': 15, 'i': 16, 'few': 17, 'please': 18, 'this': 19, 'know': 20, 'ridiculous': 21, 'concept': 22, '!': 23, 'your': 24, 'idea': 25, 'not': 26, 'entirely': 27, 'crazy': 28, 'man': 29, 's': 30, 'worth': 31, 'lies': 32, 'very': 33, 'wrong': 34, 'all': 35, 'three': 36, 'of': 37, 'need': 38, 'to': 39, 'that': 40, 'are': 41, 'another': 42, 'chance': 43, 'both': 44, 'tom': 45, 'and': 46, 'mary': 47, 'work': 48, 'as': 49, 'models': 50, 'have': 51, 'minutes': 52, 'could': 53, 'close': 54, 'door': 55, 'plant': 56, 'pumpkins': 57, 'year': 58, 'ever': 59, 'study': 60, 'library': 61, 'don': 62, 'be': 63, 'deceived': 64, 'by': 65, 'appearances': 66, 'excuse': 67, 'speak': 68, 'english': 69, 'people': 70, 'true': 71, 'meaning': 72, 'germany': 73, 'produced': 74, 'many': 75, 'scientists': 76, 'guess': 77, 'whose': 78, 'birthday': 79, 'it': 80, 'today': 81, 'acted': 82, 'like': 83, 'owned': 84, 'place': 85, 'honesty': 86, 'will': 87, 'pay': 88, 'long': 89, 'run': 90, 'how': 91, 'we': 92, 'isn': 93, 'trap': 94, 'believe': 95, 're': 96, 'up': 97}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F56F-gH2Vj-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_en = en_tokenizer.texts_to_sequences(raw_data_en)\n",
        "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,\n",
        "                                                        padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfB6anNkV_7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a47df397-da92-4e12-9c09-b69342274836"
      },
      "source": [
        "print(data_en[:3])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8  5 21 22 23  0  0  0  0  0]\n",
            " [24 25  6 26 27 28  1  0  0  0]\n",
            " [ 5 29 30 31 32  9  8  7  6  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sYXwXw9WD4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "# ATTENTION: always finish with fit_on_texts before moving on\n",
        "fr_tokenizer.fit_on_texts(raw_data_fr_in)\n",
        "fr_tokenizer.fit_on_texts(raw_data_fr_out)\n",
        "\n",
        "data_fr_in = fr_tokenizer.texts_to_sequences(raw_data_fr_in)\n",
        "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in,\n",
        "                                                           padding='post')\n",
        "\n",
        "data_fr_out = fr_tokenizer.texts_to_sequences(raw_data_fr_out)\n",
        "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out,\n",
        "                                                            padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qobqu_sgWjpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "218b1a8a-7dd7-40a7-a6e5-302a6107e715"
      },
      "source": [
        "print(data_fr_in[:3])\n",
        "print(\"+++++++++++++\")\n",
        "print(data_fr_out[:3])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3 31 32 33 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 3 34 35 20  6 10 36 37  2  0  0  0  0  0]\n",
            " [ 3 11 38 21 22 39 40 41 12 17  7  6  2  0]]\n",
            "+++++++++++++\n",
            "[[31 32 33 16  4  0  0  0  0  0  0  0  0  0]\n",
            " [34 35 20  6 10 36 37  2  4  0  0  0  0  0]\n",
            " [11 38 21 22 39 40 41 12 17  7  6  2  4  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSw8dLRcWtqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (data_en, data_fr_in, data_fr_out))\n",
        "dataset = dataset.shuffle(20).batch(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAz9nOPZXFfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3735a247-48e6-4cd5-adcb-aa19d13e6d84"
      },
      "source": [
        "for i in dataset:\n",
        "  print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
            "array([[ 8,  5, 21, 22, 23,  0,  0,  0,  0,  0],\n",
            "       [62, 12, 63, 64, 65, 66,  1,  0,  0,  0],\n",
            "       [10,  2, 59, 60,  9,  4, 61,  3,  0,  0],\n",
            "       [44, 45, 46, 47, 48, 49, 50,  1,  0,  0],\n",
            "       [17, 70, 20,  4, 71, 72,  1,  0,  0,  0]], dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[ 3, 31, 32, 33, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [ 3, 29,  1, 74, 10, 75, 76, 18, 77,  2,  0,  0,  0,  0],\n",
            "       [ 3,  6, 12, 19,  1, 71,  8, 11, 72, 28, 73,  5,  0,  0],\n",
            "       [ 3, 53, 54, 55, 56, 25, 18, 57, 26, 58,  2,  0,  0,  0],\n",
            "       [ 3, 82,  9, 83, 84, 12, 19, 24, 85, 86, 87,  2,  0,  0]],\n",
            "      dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[31, 32, 33, 16,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       [29,  1, 74, 10, 75, 76, 18, 77,  2,  4,  0,  0,  0,  0],\n",
            "       [ 6, 12, 19,  1, 71,  8, 11, 72, 28, 73,  5,  4,  0,  0],\n",
            "       [53, 54, 55, 56, 25, 18, 57, 26, 58,  2,  4,  0,  0,  0],\n",
            "       [82,  9, 83, 84, 12, 19, 24, 85, 86, 87,  2,  4,  0,  0]],\n",
            "      dtype=int32)>)\n",
            "(<tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
            "array([[ 8,  7, 13,  6, 33, 34,  1,  0,  0,  0],\n",
            "       [77, 78, 79, 80,  6, 81,  1,  0,  0,  0],\n",
            "       [11, 16, 51,  5, 17, 52, 18,  3,  0,  0],\n",
            "       [13,  2, 56, 57, 19, 58,  3,  0,  0,  0],\n",
            "       [67, 15,  1, 11,  2, 68, 69,  3,  0,  0]], dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[ 3, 12, 17,  7,  8, 42,  6, 43, 44,  2,  0,  0,  0,  0],\n",
            "       [ 3, 92,  9, 93, 94,  6, 15, 95, 96, 97, 16,  0,  0,  0],\n",
            "       [ 3, 59, 13, 60, 61, 62, 13,  1, 27,  5,  0,  0,  0,  0],\n",
            "       [ 3, 67, 68, 23,  1, 69, 28, 70,  5,  0,  0,  0,  0,  0],\n",
            "       [ 3, 13,  1, 27,  9, 78, 79, 16, 30,  1, 80, 81,  5,  0]],\n",
            "      dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[12, 17,  7,  8, 42,  6, 43, 44,  2,  4,  0,  0,  0,  0],\n",
            "       [92,  9, 93, 94,  6, 15, 95, 96, 97, 16,  4,  0,  0,  0],\n",
            "       [59, 13, 60, 61, 62, 13,  1, 27,  5,  4,  0,  0,  0,  0],\n",
            "       [67, 68, 23,  1, 69, 28, 70,  5,  4,  0,  0,  0,  0,  0],\n",
            "       [13,  1, 27,  9, 78, 79, 16, 30,  1, 80, 81,  5,  4,  0]],\n",
            "      dtype=int32)>)\n",
            "(<tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
            "array([[41,  2, 14, 15, 42, 43,  3,  0,  0,  0],\n",
            "       [ 7, 82, 83,  7, 84,  4, 85,  1,  0,  0],\n",
            "       [16, 11, 12, 95,  2, 96, 14, 97,  1,  0],\n",
            "       [35, 36, 37,  2, 38, 39, 10, 40,  1,  0],\n",
            "       [86, 87, 88,  9,  4, 89, 90,  1,  0,  0]], dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[  3,  48,  49,   1,  50,  51,  52,   5,   0,   0,   0,   0,   0,\n",
            "          0],\n",
            "       [  3,   7,  14,   6,  98,  26,  14,   7,  99,  15, 100,   2,   0,\n",
            "          0],\n",
            "       [  3,  13,  20, 107,  10,   8, 108,  19,   1, 109,   2,   0,   0,\n",
            "          0],\n",
            "       [  3,   1,  23,  45,   9,  46,  24,  25,  18,  47,   2,   0,   0,\n",
            "          0],\n",
            "       [  3,  15, 101, 102,   8,  11, 103,   2,   0,   0,   0,   0,   0,\n",
            "          0]], dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[ 48,  49,   1,  50,  51,  52,   5,   4,   0,   0,   0,   0,   0,\n",
            "          0],\n",
            "       [  7,  14,   6,  98,  26,  14,   7,  99,  15, 100,   2,   4,   0,\n",
            "          0],\n",
            "       [ 13,  20, 107,  10,   8, 108,  19,   1, 109,   2,   4,   0,   0,\n",
            "          0],\n",
            "       [  1,  23,  45,   9,  46,  24,  25,  18,  47,   2,   4,   0,   0,\n",
            "          0],\n",
            "       [ 15, 101, 102,   8,  11, 103,   2,   4,   0,   0,   0,   0,   0,\n",
            "          0]], dtype=int32)>)\n",
            "(<tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
            "array([[ 5, 29, 30, 31, 32,  9,  8,  7,  6,  1],\n",
            "       [53,  2, 54,  4, 55, 18,  3,  0,  0,  0],\n",
            "       [24, 25,  6, 26, 27, 28,  1,  0,  0,  0],\n",
            "       [91, 10, 92, 20, 19, 93, 12,  5, 94,  3],\n",
            "       [73, 74, 75, 76,  1,  0,  0,  0,  0,  0]], dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[  3,  11,  38,  21,  22,  39,  40,  41,  12,  17,   7,   6,   2,\n",
            "          0],\n",
            "       [  3,  63,   1,  64,  11,  65,  14,   7,   1,  66,   5,   0,   0,\n",
            "          0],\n",
            "       [  3,  34,  35,  20,   6,  10,  36,  37,   2,   0,   0,   0,   0,\n",
            "          0],\n",
            "       [  3, 104,  30,   1,  17,   7,  29,  14, 105,  10,  21,  22, 106,\n",
            "          5],\n",
            "       [  3,  15,  88,   8,  89,  90,   9,  91,   2,   0,   0,   0,   0,\n",
            "          0]], dtype=int32)>, <tf.Tensor: shape=(5, 14), dtype=int32, numpy=\n",
            "array([[ 11,  38,  21,  22,  39,  40,  41,  12,  17,   7,   6,   2,   4,\n",
            "          0],\n",
            "       [ 63,   1,  64,  11,  65,  14,   7,   1,  66,   5,   4,   0,   0,\n",
            "          0],\n",
            "       [ 34,  35,  20,   6,  10,  36,  37,   2,   4,   0,   0,   0,   0,\n",
            "          0],\n",
            "       [104,  30,   1,  17,   7,  29,  14, 105,  10,  21,  22, 106,   5,\n",
            "          4],\n",
            "       [ 15,  88,   8,  89,  90,   9,  91,   2,   4,   0,   0,   0,   0,\n",
            "          0]], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdf-7gTMXPZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            lstm_size, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, sequence, states):\n",
        "        embed = self.embedding(sequence)\n",
        "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        return (tf.zeros([batch_size, self.lstm_size]),\n",
        "                tf.zeros([batch_size, self.lstm_size]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvrJB5UOd7z-",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://machinetalk.org/wp-content/uploads/2019/03/data_shapes-1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmMDrCBHd1aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Decoder\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,embedding_size,lstm_size):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.lstm_size = lstm_size\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
        "    self.lstm = tf.keras.layers.LSTM(lstm_size,return_sequences=True,return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "  def call(self,sequence,state):\n",
        "\n",
        "    embed = self.embedding(sequence)\n",
        "    lstm_out, state_h, state_c = self.lstm(embed,state)\n",
        "\n",
        "    logits = self.dense(lstm_out)\n",
        "\n",
        "    return logits, state_h, state_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzCGmv3jhyl6",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://machinetalk.org/wp-content/uploads/2019/03/data_shapes-2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5PENkBvhuDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2322d5da-6251-4d43-fb07-213197a06ab8"
      },
      "source": [
        "EMBEDDING_SIZE = 32\n",
        "LSTM_SIZE = 64\n",
        "\n",
        "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "encoder = Encoder(en_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
        "\n",
        "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "decoder = Decoder(fr_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
        "\n",
        "source_input = tf.constant([[1, 3, 5, 7, 2, 0, 0, 0]])\n",
        "initial_state = encoder.init_states(1)\n",
        "encoder_output, en_state_h, en_state_c = encoder(source_input, initial_state)\n",
        "\n",
        "target_input = tf.constant([[1, 4, 6, 9, 2, 0, 0]])\n",
        "decoder_output, de_state_h, de_state_c = decoder(target_input, (en_state_h, en_state_c))\n",
        "\n",
        "print('Source sequences', source_input.shape)\n",
        "print('Encoder outputs', encoder_output.shape)\n",
        "print('Encoder state_h', en_state_h.shape)\n",
        "print('Encoder state_c', en_state_c.shape)\n",
        "\n",
        "print('\\nDestination vocab size', fr_vocab_size)\n",
        "print('Destination sequences', target_input.shape)\n",
        "print('Decoder outputs', decoder_output.shape)\n",
        "print('Decoder state_h', de_state_h.shape)\n",
        "print('Decoder state_c', de_state_c.shape)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source sequences (1, 8)\n",
            "Encoder outputs (1, 8, 64)\n",
            "Encoder state_h (1, 64)\n",
            "Encoder state_c (1, 64)\n",
            "\n",
            "Destination vocab size 110\n",
            "Destination sequences (1, 7)\n",
            "Decoder outputs (1, 7, 110)\n",
            "Decoder state_h (1, 64)\n",
            "Decoder state_c (1, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Gzp59hiZhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True)\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV3XCvafk0y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6lS4ZKKk8RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
        "    with tf.GradientTape() as tape:\n",
        "        en_outputs = encoder(source_seq, en_initial_states)\n",
        "        en_states = en_outputs[1:]\n",
        "        de_states = en_states\n",
        "\n",
        "        de_outputs = decoder(target_seq_in, de_states)\n",
        "        logits = de_outputs[0]\n",
        "        loss = loss_func(target_seq_out, logits)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKhglMKQpy4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict():\n",
        "    test_source_text = raw_data_en[np.random.choice(len(raw_data_en))]\n",
        "    print(test_source_text)\n",
        "    test_source_seq = en_tokenizer.texts_to_sequences([test_source_text])\n",
        "    print(test_source_seq)\n",
        "\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
        "\n",
        "    de_input = tf.constant([[fr_tokenizer.word_index['<start>']]])\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    out_words = []\n",
        "\n",
        "    while True:\n",
        "        de_output, de_state_h, de_state_c = decoder(\n",
        "            de_input, (de_state_h, de_state_c))\n",
        "        de_input = tf.argmax(de_output, -1)\n",
        "        out_words.append(fr_tokenizer.index_word[de_input.numpy()[0][0]])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "            break\n",
        "\n",
        "    print(' '.join(out_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAf6tInvzrwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fcff79e2-e612-4d49-9f7d-dd18b8564f2a"
      },
      "source": [
        "NUM_EPOCHS = 250\n",
        "BATCH_SIZE = 5\n",
        "\n",
        "for e in range(NUM_EPOCHS):\n",
        "    en_initial_states = encoder.init_states(BATCH_SIZE)\n",
        "\n",
        "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "        loss = train_step(source_seq, target_seq_in,\n",
        "                          target_seq_out, en_initial_states)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(e + 1, loss.numpy()))\n",
        "    \n",
        "    try:\n",
        "        predict()\n",
        "    except Exception:\n",
        "      continue"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 3.1537\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous . prie . prie prie . prie quelques quelques fermer je vous <end>\n",
            "Epoch 2 Loss 2.9474\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous . <end>\n",
            "Epoch 3 Loss 3.6079\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "vous vous . <end>\n",
            "Epoch 4 Loss 3.7928\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "vous vous . <end>\n",
            "Epoch 5 Loss 3.4363\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "vous vous . <end>\n",
            "Epoch 6 Loss 3.0563\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous vous vous . <end>\n",
            "Epoch 7 Loss 3.2204\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "vous vous vous . . <end>\n",
            "Epoch 8 Loss 3.4500\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous vous vous . . <end>\n",
            "Epoch 9 Loss 3.4032\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "vous vous vous . <end>\n",
            "Epoch 10 Loss 3.1063\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "vous vous vous <end>\n",
            "Epoch 11 Loss 3.4015\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "vous vous vous <end>\n",
            "Epoch 12 Loss 3.0170\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous vous vous vous <end>\n",
            "Epoch 13 Loss 3.5593\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "vous vous vous vous vous vous <end>\n",
            "Epoch 14 Loss 2.8605\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "vous vous vous vous <end>\n",
            "Epoch 15 Loss 3.2429\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous vous vous vous vous <end>\n",
            "Epoch 16 Loss 2.9611\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "vous vous vous vous vous <end>\n",
            "Epoch 17 Loss 3.3122\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous vous vous vous vous vous <end>\n",
            "Epoch 18 Loss 3.2120\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous vous vous vous vous <end>\n",
            "Epoch 19 Loss 2.7067\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "vous vous vous vous . <end>\n",
            "Epoch 20 Loss 2.7498\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "vous vous vous vous vous vous vous <end>\n",
            "Epoch 21 Loss 3.0896\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous vous vous vous . <end>\n",
            "Epoch 22 Loss 2.4343\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "vous . <end>\n",
            "Epoch 23 Loss 2.6177\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous vous vous . <end>\n",
            "Epoch 24 Loss 2.5343\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous vous vous vous <end>\n",
            "Epoch 25 Loss 2.4388\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "vous vous vous . <end>\n",
            "Epoch 26 Loss 2.8583\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "vous vous vous vous vous <end>\n",
            "Epoch 27 Loss 2.3801\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous vous vous vous vous . <end>\n",
            "Epoch 28 Loss 2.6818\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "vous vous vous vous . <end>\n",
            "Epoch 29 Loss 2.8764\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous vous vous vous vous . <end>\n",
            "Epoch 30 Loss 2.9847\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "vous vous vous vous vous vous . <end>\n",
            "Epoch 31 Loss 2.6501\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "<end>\n",
            "Epoch 32 Loss 2.4833\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "vous vous . <end>\n",
            "Epoch 33 Loss 2.2475\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "vous vous vous ? <end>\n",
            "Epoch 34 Loss 2.8281\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "vous vous vous vous vous . <end>\n",
            "Epoch 35 Loss 2.6976\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous vous vous vous . <end>\n",
            "Epoch 36 Loss 2.3518\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "je vous vous pas . <end>\n",
            "Epoch 37 Loss 2.4600\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous vous vous a a vous . <end>\n",
            "Epoch 38 Loss 2.6387\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "je vous vous pas . <end>\n",
            "Epoch 39 Loss 2.2110\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "vous vous ? <end>\n",
            "Epoch 40 Loss 2.3653\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous vous vous a a . <end>\n",
            "Epoch 41 Loss 2.3405\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "je vous vous pas les . <end>\n",
            "Epoch 42 Loss 2.4590\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "vous vous vous les . <end>\n",
            "Epoch 43 Loss 2.0841\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous vous vous a a les . <end>\n",
            "Epoch 44 Loss 2.4037\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "vous vous pas . <end>\n",
            "Epoch 45 Loss 2.1191\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "vous vous a a les . <end>\n",
            "Epoch 46 Loss 2.1753\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous vous de a pas les . <end>\n",
            "Epoch 47 Loss 2.3871\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "vous vous pas les . <end>\n",
            "Epoch 48 Loss 2.2791\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "vous vous de a a vous . <end>\n",
            "Epoch 49 Loss 2.2191\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n pas pas les les . <end>\n",
            "Epoch 50 Loss 2.0809\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "dans ce il il est est . <end>\n",
            "Epoch 51 Loss 2.2997\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je vous vous a a pas les ? <end>\n",
            "Epoch 52 Loss 2.1296\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "vous vous pas pas . <end>\n",
            "Epoch 53 Loss 1.9835\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "vous vous de a a vous des ? <end>\n",
            "Epoch 54 Loss 2.0990\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous vous de a la vous . <end>\n",
            "Epoch 55 Loss 2.0568\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "dans ce il il est est . <end>\n",
            "Epoch 56 Loss 2.1231\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous vous a a des . <end>\n",
            "Epoch 57 Loss 2.0115\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je vous vous vous les ? <end>\n",
            "Epoch 58 Loss 1.9750\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "<end>\n",
            "Epoch 59 Loss 2.0156\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "<end>\n",
            "Epoch 60 Loss 1.7892\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je vous vous vous les ? <end>\n",
            "Epoch 61 Loss 2.2224\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "je vous vous pas les ? <end>\n",
            "Epoch 62 Loss 1.9348\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "vous vous de vous a a a des des ? <end>\n",
            "Epoch 63 Loss 1.6528\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je vous de vous pas cela les les . <end>\n",
            "Epoch 64 Loss 1.7389\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "vous vous de a a la des ? <end>\n",
            "Epoch 65 Loss 1.6565\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "tom n pas pas les les . <end>\n",
            "Epoch 66 Loss 1.9907\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "je vous de vous pas cela les les . <end>\n",
            "Epoch 67 Loss 1.7442\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "<end>\n",
            "Epoch 68 Loss 1.7568\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et travaillent tous les les les les . <end>\n",
            "Epoch 69 Loss 1.5436\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "vous de pas pas les . <end>\n",
            "Epoch 70 Loss 1.5434\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous de pas tous les . <end>\n",
            "Epoch 71 Loss 1.4772\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "vous de est il il il . <end>\n",
            "Epoch 72 Loss 1.3951\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "je vous de vous cela tous les les . <end>\n",
            "Epoch 73 Loss 1.2373\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de de cela tous les les . <end>\n",
            "Epoch 74 Loss 1.4517\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "ce vous est il il il . <end>\n",
            "Epoch 75 Loss 1.4178\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "vous de pas pas les . <end>\n",
            "Epoch 76 Loss 1.5629\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "je vous pas pas les ? <end>\n",
            "Epoch 77 Loss 1.5699\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous avez pas tous . <end>\n",
            "Epoch 78 Loss 1.5089\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je vous minutes vous vous ? <end>\n",
            "Epoch 79 Loss 1.2246\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce est est est . <end>\n",
            "Epoch 80 Loss 1.3769\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "vous de de vous cela cela les les . <end>\n",
            "Epoch 81 Loss 1.1412\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous de pas tous les . <end>\n",
            "Epoch 82 Loss 1.5319\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de de cela cela tous les . <end>\n",
            "Epoch 83 Loss 1.4174\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "ce est est . <end>\n",
            "Epoch 84 Loss 1.4470\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "reside ce il . <end>\n",
            "Epoch 85 Loss 1.1160\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je vous minutes vous vous ? <end>\n",
            "Epoch 86 Loss 1.3472\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous de pas tous les . <end>\n",
            "Epoch 87 Loss 1.1907\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "ce vous qu il il s s il il . <end>\n",
            "Epoch 88 Loss 1.2599\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "ce vous qu a a la la . <end>\n",
            "Epoch 89 Loss 1.3504\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "ce il est il il il . <end>\n",
            "Epoch 90 Loss 1.0324\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je vous minutes vous prie ? <end>\n",
            "Epoch 91 Loss 1.1887\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me vous une chance ? <end>\n",
            "Epoch 92 Loss 1.3881\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "vous avez vous abuser les les . <end>\n",
            "Epoch 93 Loss 1.1930\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce est est est . <end>\n",
            "Epoch 94 Loss 1.2609\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom mary travaillent travaillent tous les les mannequins . <end>\n",
            "Epoch 95 Loss 1.0077\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "ce est est est il ! <end>\n",
            "Epoch 96 Loss 1.2091\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "ce vous qu il il il il . <end>\n",
            "Epoch 97 Loss 1.0199\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "vous de de faire cela cela les les trois . <end>\n",
            "Epoch 98 Loss 1.3483\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment vous vous a a a la bibliotheque des ? <end>\n",
            "Epoch 99 Loss 1.1317\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de de cela cela tous les . <end>\n",
            "Epoch 100 Loss 1.1592\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "quel est ! <end>\n",
            "Epoch 101 Loss 0.8826\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous de de pas cela cela les dire . <end>\n",
            "Epoch 102 Loss 0.9662\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment vous vous a a a la bibliotheque des ? <end>\n",
            "Epoch 103 Loss 1.0869\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "n n est pas completement . <end>\n",
            "Epoch 104 Loss 1.1642\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "ce est est est il ! <end>\n",
            "Epoch 105 Loss 0.9043\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez de faire cela tous les les . <end>\n",
            "Epoch 106 Loss 0.7084\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je avoir minutes vous prie ? <end>\n",
            "Epoch 107 Loss 0.9291\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "quel est ! <end>\n",
            "Epoch 108 Loss 0.8912\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "vous de de faire cela cela tous les trois . <end>\n",
            "Epoch 109 Loss 0.9870\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "ce est est il ! <end>\n",
            "Epoch 110 Loss 0.9209\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me vous une chance ? <end>\n",
            "Epoch 111 Loss 1.0900\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "ce est est il ! <end>\n",
            "Epoch 112 Loss 0.7095\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "valeur valeur un homme reside ce ce il est . <end>\n",
            "Epoch 113 Loss 0.8861\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "valeur valeur un homme reside dans ce qu il est . <end>\n",
            "Epoch 114 Loss 0.8838\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment vous qu il il s s il l ? <end>\n",
            "Epoch 115 Loss 0.8954\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me vous une chance ? <end>\n",
            "Epoch 116 Loss 0.9508\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "je je avoir minutes vous prie ? <end>\n",
            "Epoch 117 Loss 0.8021\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "valeur valeur un homme reside dans ce qu il est . <end>\n",
            "Epoch 118 Loss 0.8064\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez de faire cela tous les trois . <end>\n",
            "Epoch 119 Loss 0.8624\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et mary travaillent tous les deux mannequins . <end>\n",
            "Epoch 120 Loss 0.7788\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je n n pas a croire vous abandonniez . <end>\n",
            "Epoch 121 Loss 0.7018\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me donnez vous autre chance ? <end>\n",
            "Epoch 122 Loss 0.6428\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il est tres . <end>\n",
            "Epoch 123 Loss 0.5003\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il est tres . <end>\n",
            "Epoch 124 Loss 0.8383\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "je vous pas abuser par les ? <end>\n",
            "Epoch 125 Loss 0.9275\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de qui pas pas veut reellement <end>\n",
            "Epoch 126 Loss 0.5995\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous laissez pas abuser les <end>\n",
            "Epoch 127 Loss 0.5418\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "quel est ! <end>\n",
            "Epoch 128 Loss 0.5509\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je n n pas a croire que vous . <end>\n",
            "Epoch 129 Loss 0.4353\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "valeur un homme reside ce ce qu il . <end>\n",
            "Epoch 130 Loss 0.5839\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment vous qu il s il s il l endroit . <end>\n",
            "Epoch 131 Loss 0.6868\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "vous de de savent cela cela veut reellement dire . <end>\n",
            "Epoch 132 Loss 0.7371\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous de de cela cela cela les dire . <end>\n",
            "Epoch 133 Loss 0.7247\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de qui c l anniversaire ! <end>\n",
            "Epoch 134 Loss 0.6153\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me donnez vous une chance ? <end>\n",
            "Epoch 135 Loss 0.6571\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et mary travaillent tous les deux mannequins . <end>\n",
            "Epoch 136 Loss 0.5768\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et mary travaillent tous les deux mannequins . <end>\n",
            "Epoch 137 Loss 0.5915\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n est pas completement folle . <end>\n",
            "Epoch 138 Loss 0.5754\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il s s il agit d un piege ? <end>\n",
            "Epoch 139 Loss 0.4722\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l paye a la longue . <end>\n",
            "Epoch 140 Loss 0.7375\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "la valeur d un homme reside dans ce qu il est . <end>\n",
            "Epoch 141 Loss 0.4547\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il est tres mal . <end>\n",
            "Epoch 142 Loss 0.4344\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "l honnetete a la longue . <end>\n",
            "Epoch 143 Loss 0.4843\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "cette avez vous plante des citrouilles ? <end>\n",
            "Epoch 144 Loss 0.5573\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "puis je avoir quelques minutes vous prie ? <end>\n",
            "Epoch 145 Loss 0.4867\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "est pas pas completement <end>\n",
            "Epoch 146 Loss 0.6085\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l paye a la longue . <end>\n",
            "Epoch 147 Loss 0.4542\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "l honnetete a la la longue . <end>\n",
            "Epoch 148 Loss 0.5472\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me donnez vous une chance ? <end>\n",
            "Epoch 149 Loss 0.6559\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il est tres mal . <end>\n",
            "Epoch 150 Loss 0.3741\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez de faire cela tous les trois . <end>\n",
            "Epoch 151 Loss 0.4154\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "l honnetete a la la longue . <end>\n",
            "Epoch 152 Loss 0.2850\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez de faire cela tous les trois . <end>\n",
            "Epoch 153 Loss 0.5122\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "cette avez vous plante des citrouilles ? <end>\n",
            "Epoch 154 Loss 0.4047\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "ce qu il est comme s il . <end>\n",
            "Epoch 155 Loss 0.3543\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me donnez vous une chance ? <end>\n",
            "Epoch 156 Loss 0.3786\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l paye a la longue . <end>\n",
            "Epoch 157 Loss 0.4334\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "puis je avoir quelques minutes vous prie ? <end>\n",
            "Epoch 158 Loss 0.3695\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous laissez pas abuser les apparences . <end>\n",
            "Epoch 159 Loss 0.3538\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 160 Loss 0.2810\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "ce qu il est comme s il possedait . <end>\n",
            "Epoch 161 Loss 0.2397\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de qui c l anniversaire ! <end>\n",
            "Epoch 162 Loss 0.3728\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 163 Loss 0.3876\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et mary travaillent tous les deux comme mannequins . <end>\n",
            "Epoch 164 Loss 0.4485\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "vous de qui c l anniversaire ! <end>\n",
            "Epoch 165 Loss 0.3557\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et mary travaillent tous les deux comme mannequins . <end>\n",
            "Epoch 166 Loss 0.2836\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "cette annee vous plante des citrouilles ? <end>\n",
            "Epoch 167 Loss 0.4215\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je n arrive pas a croire que vous abandonniez . <end>\n",
            "Epoch 168 Loss 0.3105\n",
            "Are you giving me another chance ?\n",
            "[[41, 2, 14, 15, 42, 43, 3]]\n",
            "me donnez vous une chance ? <end>\n",
            "Epoch 169 Loss 0.3434\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "valeur un homme reside ce qu il est . <end>\n",
            "Epoch 170 Loss 0.4340\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "n est pas completement <end>\n",
            "Epoch 171 Loss 0.3504\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous laissez pas abuser les apparences . <end>\n",
            "Epoch 172 Loss 0.4385\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "peu de gens savent que cela veut reellement dire . <end>\n",
            "Epoch 173 Loss 0.2664\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "peu de gens savent que cela veut reellement dire . <end>\n",
            "Epoch 174 Loss 0.2848\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "cette annee vous plante des citrouilles ? <end>\n",
            "Epoch 175 Loss 0.2829\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l paye a la longue . <end>\n",
            "Epoch 176 Loss 0.2327\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de c est l anniversaire aujourd hui ! <end>\n",
            "Epoch 177 Loss 0.2785\n",
            "Both Tom and Mary work as models .\n",
            "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
            "tom et mary travaillent tous les deux comme mannequins . <end>\n",
            "Epoch 178 Loss 0.2955\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l paye a la longue . <end>\n",
            "Epoch 179 Loss 0.2578\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
            "Epoch 180 Loss 0.3206\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez besoin de faire cela tous les trois . <end>\n",
            "Epoch 181 Loss 0.2706\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de c est l anniversaire aujourd hui ! <end>\n",
            "Epoch 182 Loss 0.2274\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 183 Loss 0.1853\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "il est est comme s il possedait l endroit . <end>\n",
            "Epoch 184 Loss 0.1717\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "il est est comme s il possedait l endroit . <end>\n",
            "Epoch 185 Loss 0.2112\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 186 Loss 0.2465\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 187 Loss 0.1963\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n est pas completement folle . <end>\n",
            "Epoch 188 Loss 0.2730\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "vous laissez pas abuser les apparences . <end>\n",
            "Epoch 189 Loss 0.2841\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de qui c est l aujourd hui ! <end>\n",
            "Epoch 190 Loss 0.2800\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "vous de gens savent ce cela veut reellement dire . <end>\n",
            "Epoch 191 Loss 0.2337\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "n est pas completement . <end>\n",
            "Epoch 192 Loss 0.1795\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "la valeur d un homme reside dans ce qu il est . <end>\n",
            "Epoch 193 Loss 0.1932\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "ne vous pas abuser par les apparences . <end>\n",
            "Epoch 194 Loss 0.2473\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il a est mal . <end>\n",
            "Epoch 195 Loss 0.1594\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n est pas completement folle . <end>\n",
            "Epoch 196 Loss 0.1708\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "n est pas completement . <end>\n",
            "Epoch 197 Loss 0.2691\n",
            "A man s worth lies in what he is .\n",
            "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
            "la valeur d un homme reside dans ce qu il est . <end>\n",
            "Epoch 198 Loss 0.1250\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "puis je avoir quelques minutes je vous ? <end>\n",
            "Epoch 199 Loss 0.2656\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de qui c est l aujourd hui ! <end>\n",
            "Epoch 200 Loss 0.1941\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
            "Epoch 201 Loss 0.1547\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "quel ridicule ! <end>\n",
            "Epoch 202 Loss 0.2050\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "pourriez vous fermer la s il vous ? <end>\n",
            "Epoch 203 Loss 0.2267\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "pourriez vous fermer la s il vous ? <end>\n",
            "Epoch 204 Loss 0.1343\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "puis je avoir quelques minutes je vous ? <end>\n",
            "Epoch 205 Loss 0.1783\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "ne vous laissez pas par les apparences . <end>\n",
            "Epoch 206 Loss 0.2144\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "peu de gens savent ce cela veut reellement dire . <end>\n",
            "Epoch 207 Loss 0.1909\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "n est pas completement . <end>\n",
            "Epoch 208 Loss 0.1584\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "ne vous laissez pas par les apparences . <end>\n",
            "Epoch 209 Loss 0.1638\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il a est tres mal . <end>\n",
            "Epoch 210 Loss 0.1559\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez besoin de faire cela tous les trois . <end>\n",
            "Epoch 211 Loss 0.1648\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "pourriez vous fermer la s il vous ? <end>\n",
            "Epoch 212 Loss 0.1634\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l paye a la longue . <end>\n",
            "Epoch 213 Loss 0.1936\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 214 Loss 0.1794\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n est pas completement folle . <end>\n",
            "Epoch 215 Loss 0.1801\n",
            "Can I have a few minutes please ?\n",
            "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
            "puis je avoir quelques minutes je vous ? <end>\n",
            "Epoch 216 Loss 0.1830\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "ne vous laissez pas par les apparences . <end>\n",
            "Epoch 217 Loss 0.1444\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez besoin de faire cela tous les trois . <end>\n",
            "Epoch 218 Loss 0.1306\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "peu de gens savent ce que veut reellement dire . <end>\n",
            "Epoch 219 Loss 0.2076\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "pourriez vous fermer la porte vous plait ? <end>\n",
            "Epoch 220 Loss 0.1759\n",
            "Do you ever study in the library ?\n",
            "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
            "est ce que vous etudiez a la bibliotheque des ? <end>\n",
            "Epoch 221 Loss 0.1872\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il a fait est . <end>\n",
            "Epoch 222 Loss 0.1404\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je n arrive pas a croire que vous abandonniez . <end>\n",
            "Epoch 223 Loss 0.1520\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je n arrive pas a croire que vous abandonniez . <end>\n",
            "Epoch 224 Loss 0.1115\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez besoin de faire cela tous les trois . <end>\n",
            "Epoch 225 Loss 0.1194\n",
            "I can t believe you re giving up .\n",
            "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
            "je n arrive pas a croire que vous abandonniez . <end>\n",
            "Epoch 226 Loss 0.1129\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "quel ridicule ! <end>\n",
            "Epoch 227 Loss 0.1667\n",
            "Could you close the door please ?\n",
            "[[53, 2, 54, 4, 55, 18, 3]]\n",
            "pourriez vous fermer la porte vous plait ? <end>\n",
            "Epoch 228 Loss 0.1409\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "peu de gens savent ce que veut reellement dire . <end>\n",
            "Epoch 229 Loss 0.1264\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "quel ridicule ! <end>\n",
            "Epoch 230 Loss 0.1280\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "quel ridicule ! <end>\n",
            "Epoch 231 Loss 0.1269\n",
            "Few people know the true meaning .\n",
            "[[17, 70, 20, 4, 71, 72, 1]]\n",
            "peu de gens savent ce que cela veut reellement . <end>\n",
            "Epoch 232 Loss 0.1395\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez besoin de faire cela tous les trois . <end>\n",
            "Epoch 233 Loss 0.1398\n",
            "Excuse me . Can you speak English ?\n",
            "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
            "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
            "Epoch 234 Loss 0.1163\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de qui c est l anniversaire aujourd <end>\n",
            "Epoch 235 Loss 0.1320\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n est pas completement folle . <end>\n",
            "Epoch 236 Loss 0.1705\n",
            "All three of you need to do that .\n",
            "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
            "vous avez besoin de faire cela tous les trois . <end>\n",
            "Epoch 237 Loss 0.1216\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "ne vous laissez pas par les apparences . <end>\n",
            "Epoch 238 Loss 0.0940\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 239 Loss 0.1238\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il a fait est . <end>\n",
            "Epoch 240 Loss 0.1040\n",
            "What he did is very wrong .\n",
            "[[8, 7, 13, 6, 33, 34, 1]]\n",
            "ce qu il a fait est . <end>\n",
            "Epoch 241 Loss 0.1102\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de qui c est l anniversaire aujourd <end>\n",
            "Epoch 242 Loss 0.1158\n",
            "Honesty will pay in the long run .\n",
            "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
            "l honnetete paye a la longue . <end>\n",
            "Epoch 243 Loss 0.0958\n",
            "Your idea is not entirely crazy .\n",
            "[[24, 25, 6, 26, 27, 28, 1]]\n",
            "votre n est pas completement folle . <end>\n",
            "Epoch 244 Loss 0.1268\n",
            "Germany produced many scientists .\n",
            "[[73, 74, 75, 76, 1]]\n",
            "n est pas completement folle . <end>\n",
            "Epoch 245 Loss 0.1187\n",
            "What a ridiculous concept !\n",
            "[[8, 5, 21, 22, 23]]\n",
            "quel ridicule ! <end>\n",
            "Epoch 246 Loss 0.1334\n",
            "Guess whose birthday it is today .\n",
            "[[77, 78, 79, 80, 6, 81, 1]]\n",
            "devine de qui c est l anniversaire aujourd <end>\n",
            "Epoch 247 Loss 0.1544\n",
            "Don t be deceived by appearances .\n",
            "[[62, 12, 63, 64, 65, 66, 1]]\n",
            "ne vous laissez pas par les apparences . <end>\n",
            "Epoch 248 Loss 0.1133\n",
            "How do we know this isn t a trap ?\n",
            "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
            "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
            "Epoch 249 Loss 0.0934\n",
            "He acted like he owned the place .\n",
            "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
            "il s est comporte comme s il possedait l endroit . <end>\n",
            "Epoch 250 Loss 0.0923\n",
            "Did you plant pumpkins this year ?\n",
            "[[13, 2, 56, 57, 19, 58, 3]]\n",
            "cette annee avez vous des citrouilles ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Rh94Y9zzhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}